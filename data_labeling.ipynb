{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"/data/Data/yntn/data_cleaned.log\"\n",
    "outfile = \"/data/Data/yntn/data_out.csv\"\n",
    "emoji_path = '/data/Data/feed_data/new_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(infile, \"r\") as f:\n",
    "    lines = f.readlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read file\n",
    "with open('emoji2code.json', 'r') as myfile:\n",
    "    data = myfile.read()\n",
    "\n",
    "# parse file\n",
    "obj = json.loads(data)\n",
    "emoji = obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "emoji_dict = {}\n",
    "\n",
    "for file_dir in Path(emoji_path).glob('**/*.png'):\n",
    "    if (str(file_dir.parent.stem) in emoji_dict):  \n",
    "        emoji_dict[str(file_dir.parent.stem)].append(str(file_dir.stem))\n",
    "    else:\n",
    "        emoji_dict[str(file_dir.parent.stem)] = [str(file_dir.stem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import csv\n",
    "import re, string\n",
    " \n",
    "with open(outfile, \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    myData = [['text','label']]\n",
    "    for line in lines:\n",
    "        if (\"feed at\" in line):\n",
    "            continue        \n",
    "                \n",
    "        count = {}\n",
    "        st = line\n",
    "        for phrase in emoji:\n",
    "            if (phrase in st):\n",
    "                count[obj[phrase]] = 0\n",
    "                while (phrase in st):\n",
    "                    count[obj[phrase]] = count[obj[phrase]] + 1\n",
    "                    st = st.replace(phrase,'',1)                    \n",
    "        emoji_max = max(count.items(), key=operator.itemgetter(1))[0] #string\n",
    "        \n",
    "        st = st.lower()\n",
    "        words = st.split()\n",
    "        words = re.split(r'\\W+', st)\n",
    "        text = ''        \n",
    "        text = ' '.join(word for word in words)\n",
    "        text = text.strip()\n",
    "        \n",
    "        if ('ttt' in text):\n",
    "            continue\n",
    "                \n",
    "        if (text == \"\") or (type(text) == float) or (str(text) =='nan'): \n",
    "            continue         \n",
    "        for etype in emoji_dict.keys():\n",
    "            if emoji_max in emoji_dict[etype]:\n",
    "                myData.append([text, etype.lower()])\n",
    "                break\n",
    "                \n",
    "    writer.writerows(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('/data/Data/yntn/data_out.csv') \n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
